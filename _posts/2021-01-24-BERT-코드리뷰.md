---
layout: post
category: MODEL
---

# BERT fine-tuning 코드 리뷰

## BERT Fine-Tuning이란?
   BERT는 대용량의 텍스트 코퍼스의 단어 임베딩을 MLM과 NSP 방식을 통해 사전학습한 transformer 모델입니다. MLM과 NSP task를 잘 수행하도록 학습된 BERT는 언어의 맥락적, 문법적 특징을 이해할 수 있다고 여겨집니다. 이와 같이 사전학습된 모델을 다시 해결하고자 하는 타겟 task를 잘 수행하도록 모델의 파라미터를 재조정하는 과정이 fine-tuning 과정입니다.<br/> 이 글에서는 multi-class text classification을 잘하도록 BERT 파라미터를 fine-tuning하는 코드를 리뷰하겠습니다.
<br/>

## BERT Fine-tuning의 main함수 구성

### 1. Configuration 초기화
```
const ultimateTruth = 'this theme is the best!';
console.log(ultimateTruth);
```

And here is some `inline code`!

### 2. DataLoader 만들기

### 3. Model 정의

### 4. Train 과정

### 5. Eval 과정
